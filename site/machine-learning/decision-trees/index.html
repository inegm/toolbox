
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="canonical" href="https://example.com/machine-learning/decision-trees/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.1, mkdocs-material-7.1.8">
    
    
      
        <title>Decision-trees - Toolbox</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.ca7ac06f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.f1a3b89f.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#decision-trees" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Toolbox" class="md-header__button md-logo" aria-label="Toolbox" data-md-component="logo">
      
  <img src="../../assets/logo_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Toolbox
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Decision-trees
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/inegm/toolbox/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    inegm/toolbox
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Toolbox" class="md-nav__button md-logo" aria-label="Toolbox" data-md-component="logo">
      
  <img src="../../assets/logo_white.png" alt="logo">

    </a>
    Toolbox
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/inegm/toolbox/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    inegm/toolbox
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      <label class="md-nav__link" for="__nav_2">
        Machine-learning
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Machine-learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Machine-learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Decision-trees
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Decision-trees
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier" class="md-nav__link">
    DecisionTreeClassifier
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.tree" class="md-nav__link">
    tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.evaluate" class="md-nav__link">
    evaluate()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.find_best_split" class="md-nav__link">
    find_best_split()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.fit" class="md-nav__link">
    fit()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.information_gain" class="md-nav__link">
    information_gain()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.predict" class="md-nav__link">
    predict()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.gini_impurity" class="md-nav__link">
    gini_impurity()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.entropy" class="md-nav__link">
    entropy()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../evaluation/" class="md-nav__link">
        Evaluation
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        Optimization
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Optimization" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Optimization
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../optimization/particle-swarm/" class="md-nav__link">
        Particle-swarm
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        Sorting
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Sorting" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Sorting
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../sorting/quicksort/" class="md-nav__link">
        quicksort
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier" class="md-nav__link">
    DecisionTreeClassifier
  </a>
  
    <nav class="md-nav" aria-label="DecisionTreeClassifier">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.tree" class="md-nav__link">
    tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.evaluate" class="md-nav__link">
    evaluate()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.find_best_split" class="md-nav__link">
    find_best_split()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.fit" class="md-nav__link">
    fit()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.information_gain" class="md-nav__link">
    information_gain()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.predict" class="md-nav__link">
    predict()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.gini_impurity" class="md-nav__link">
    gini_impurity()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.decisiontree.entropy" class="md-nav__link">
    entropy()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/inegm/toolbox/edit/master/docs/machine-learning/decision-trees.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="decision-trees">Decision Trees</h1>


  <div class="doc doc-object doc-class">



<h2 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier" class="doc doc-heading">
        <code>DecisionTreeClassifier</code>



</h2>

    <div class="doc doc-contents first">

      <p><strong>Caveat</strong></p>
<p>This is a simple, pedagogical implementation of a decision-tree classifier.
It is not likely to win you any Kaggle competitions on its own. It
typically achieves accuracy scores around 0.7 and is slow to train.
That said, this is what RandomForest, Ensemble methods, and XGBoost are
based on, so it's well worth understanding how it works.</p>
<p><strong>Fitting the tree</strong></p>
<p>These classifiers work by recursively splitting a dataset using <strong>queries</strong>
on the features in such a way as to maximize <strong>information gain</strong> at each new
split. Information gain is calculated for each split by using an <strong>impurity
function</strong>, which is sometimes known as an <em>error function</em>. Queries can be
as complex as the implementer cares to make them, but in this implementation
they are simple : all queries here are of the form <span class="arithmatex">\(v \ge w\)</span>. A value <span class="arithmatex">\(w\)</span> is
selected from the features and a candidate split is created : all examples
for which the query yields True go to the left child and all others go to the
right child. The candidate information gain is then evaluated. This process
is repeated for each feature and for each unique feature value. The actual
split is chosen to be the candidate with the highest information gain. For
more on information gain, see the <a href="#toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.information_gain">information_gain</a>
method's documentation. The leaves of the tree contain subsets of the dataset
with no impurity, that is to say all examples of the subset belong to a
single class.</p>
<p><strong>Making predictions</strong></p>
<p>By traveling through the tree with a novel, unlabeled example, applying the
queries to its features' values to determine the path, we end up at a leaf
node which determines the predicted class label for the novel example.</p>

<p><strong>Examples:</strong></p>
    <div class="highlight"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;/&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
    <span class="s2">&quot;https://archive.ics.uci.edu&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ml/machine-learning-databases&quot;</span><span class="p">,</span>
    <span class="s2">&quot;heart-disease/processed.cleveland.data&quot;</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
        <span class="n">url</span><span class="p">,</span>
        <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">names</span><span class="o">=</span><span class="p">[</span>
            <span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;sex&quot;</span><span class="p">,</span> <span class="s2">&quot;cp&quot;</span><span class="p">,</span> <span class="s2">&quot;trestbps&quot;</span><span class="p">,</span> <span class="s2">&quot;chol&quot;</span><span class="p">,</span> <span class="s2">&quot;fbs&quot;</span><span class="p">,</span> <span class="s2">&quot;restecg&quot;</span><span class="p">,</span>
            <span class="s2">&quot;thalach&quot;</span><span class="p">,</span> <span class="s2">&quot;exang&quot;</span><span class="p">,</span> <span class="s2">&quot;oldpeak&quot;</span><span class="p">,</span> <span class="s2">&quot;slope&quot;</span><span class="p">,</span> <span class="s2">&quot;ca&quot;</span><span class="p">,</span> <span class="s2">&quot;thal&quot;</span><span class="p">,</span> <span class="s2">&quot;target&quot;</span>
        <span class="p">]</span>
    <span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="mi">2</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span><span class="mi">1</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">train</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="mi">201</span><span class="p">]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">test</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">201</span><span class="p">:]</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dtc</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">gini_impurity</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">dtc</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>  <span class="c1"># 2 minute coffee break</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">_</span> <span class="o">=</span> <span class="n">dtc</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</code></pre></div>
    <pre><code>MODEL

Precision           mean        0.688657
                    weighted    0.696078
Precision negative  mean        0.688657
                    weighted    0.681236
Sensitivity         mean        0.703326
                    weighted    0.701773
Specificity         mean        0.703326
                    weighted    0.704880
Accuracy            mean        0.696078
                    weighted    0.696078
F1-score            mean        0.687395
                    weighted    0.690460
dtype: float64

CLASSES

                            0          1
True Positives      44.000000  27.000000
True Negatives      27.000000  44.000000
False Positives     10.000000  21.000000
False Negatives     21.000000  10.000000
Precision            0.814815   0.562500
Precision negative   0.562500   0.814815
Sensitivity          0.676923   0.729730
Specificity          0.729730   0.676923
Accuracy             0.696078   0.696078
F1-score             0.739496   0.635294
Weight (actual)      0.529412   0.470588

CONFUSION MATRIX

        0   1
actual
0       44  10
1       21  27
</code></pre>
      <p><strong>A comparison</strong></p>
<p>The accuracy score for the given example is of 0.70, which is not far from
scikit-learn's DecisionTreeClassifier accuracy of 0.76 given the same dataset.
That said, with hyperparameter tuning (not possible here), the scikit-learn
implementation can reach much higher accuracy scores (above 0.85).</p>




  <div class="doc doc-children">






  <div class="doc doc-object doc-attribute">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.tree" class="doc doc-heading">
<code class="highlight language-python"><span class="n">tree</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pointer to the decision-tree's root node.</p>
<p>The (binary) tree can be traversed by traveling through each node's
left (True) and right (False) child nodes.</p>
    </div>

  </div>






  <div class="doc doc-object doc-method">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">labels_col</span><span class="p">,</span> <span class="n">impurity_func</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">


<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>dataset</code></td>
        <td><code>pd.DataFrame</code></td>
        <td><p>Including one or more feature columns and a single labels
column.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>labels_col</code></td>
        <td><code>str</code></td>
        <td><p>The name of the labels column.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>impurity_func</code></td>
        <td><code>Callable</code></td>
        <td><p>Options include <a href="#toolbox.algorithms.learning.decisiontree.gini_impurity">gini_impurity</a> and
<a href="#toolbox.algorithms.learning.decisiontree.entropy">entropy</a>,
but any callable with the same signature which returns a float
will do.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">labels_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">impurity_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        dataset: Including one or more feature columns and a single labels</span>
<span class="sd">            column.</span>
<span class="sd">        labels_col: The name of the labels column.</span>
<span class="sd">        impurity_func: Options include [gini_impurity]</span>
<span class="sd">            [toolbox.algorithms.learning.decisiontree.gini_impurity] and</span>
<span class="sd">            [entropy][toolbox.algorithms.learning.decisiontree.entropy],</span>
<span class="sd">            but any callable with the same signature which returns a float</span>
<span class="sd">            will do.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels_col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">labels_col</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">impurity_func</span> <span class="o">=</span> <span class="n">impurity_func</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_tree</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.evaluate" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Evaluate the performance of the decision-tree model.</p>
<p>See
<a href="../evaluation/#toolbox.algorithms.learning.evaluation.evaluate_classifier">evaluation.evaluate_classifier</a>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>data</code></td>
        <td><code>pd.DataFrame</code></td>
        <td><p>A labeled DataFrame. The label column is expected to be named
the same as the labels Series that was provided at initialization.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Evaluate the performance of the decision-tree model.</span>

<span class="sd">    See</span>
<span class="sd">    [evaluation.evaluate_classifier]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_classifier].</span>

<span class="sd">    Args:</span>
<span class="sd">        data: A labeled DataFrame. The label column is expected to be named</span>
<span class="sd">            the same as the labels Series that was provided at initialization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">predict_col</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
    <span class="n">actual_col</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">predict_col</span><span class="p">,</span> <span class="s2">&quot;actual&quot;</span><span class="p">])</span>

    <span class="n">pred_df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">predict_col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">pred_df</span><span class="p">[</span><span class="n">actual_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">predict_col</span><span class="p">]</span>

    <span class="n">model_eval</span><span class="p">,</span> <span class="n">class_eval</span><span class="p">,</span> <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">evaluate_classifier</span><span class="p">(</span>
        <span class="n">predict_df</span><span class="o">=</span><span class="n">pred_df</span><span class="p">,</span>
        <span class="n">predict_col</span><span class="o">=</span><span class="n">predict_col</span><span class="p">,</span>
        <span class="n">actual_col</span><span class="o">=</span><span class="n">actual_col</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">model_eval</span><span class="p">,</span> <span class="n">class_eval</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.find_best_split" class="doc doc-heading">
<code class="highlight language-python"><span class="n">find_best_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Find the split which yields the highest information gain.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>idx</code></td>
        <td><code>Any</code></td>
        <td><p>The (pandas array) index of the examples of the node
before the split.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">find_best_split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Find the split which yields the highest information gain.</span>

<span class="sd">    Args:</span>
<span class="sd">        idx (pd.array): The (pandas array) index of the examples of the node</span>
<span class="sd">            before the split.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_gain</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">query</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">true_idx</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">false_idx</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">():</span>
            <span class="n">split_condition</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
            <span class="n">n_true</span> <span class="o">=</span> <span class="n">split_condition</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">n_false</span> <span class="o">=</span> <span class="n">split_condition</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">n_true</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">n_false</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="n">gain</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">information_gain</span><span class="p">(</span><span class="n">idx</span><span class="o">=</span><span class="n">idx</span><span class="p">,</span> <span class="n">true_idx</span><span class="o">=</span><span class="n">split_condition</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;=</span> <span class="n">max_gain</span><span class="p">:</span>
                <span class="n">true_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">split_condition</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
                <span class="n">false_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="o">~</span><span class="n">split_condition</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
                <span class="n">max_gain</span> <span class="o">=</span> <span class="n">gain</span>
                <span class="n">query</span> <span class="o">=</span> <span class="n">DTCQuery</span><span class="p">(</span><span class="n">feature</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">ge</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">max_gain</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">true_idx</span><span class="p">,</span> <span class="n">false_idx</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Build the decision tree.</p>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Build the decision tree.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_fit</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
        <span class="n">gain</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">left_idx</span><span class="p">,</span> <span class="n">right_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_best_split</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">idx</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">gain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">DTCNode</span><span class="p">(</span>
                <span class="n">node</span><span class="o">.</span><span class="n">idx</span><span class="p">,</span> <span class="n">leaf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="n">node</span><span class="o">.</span><span class="n">query</span> <span class="o">=</span> <span class="n">query</span>
        <span class="n">node</span><span class="o">.</span><span class="n">left</span> <span class="o">=</span> <span class="n">_fit</span><span class="p">(</span><span class="n">DTCNode</span><span class="p">(</span><span class="n">left_idx</span><span class="p">))</span>
        <span class="n">node</span><span class="o">.</span><span class="n">right</span> <span class="o">=</span> <span class="n">_fit</span><span class="p">(</span><span class="n">DTCNode</span><span class="p">(</span><span class="n">right_idx</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">node</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_tree</span> <span class="o">=</span> <span class="n">_fit</span><span class="p">(</span><span class="n">DTCNode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.information_gain" class="doc doc-heading">
<code class="highlight language-python"><span class="n">information_gain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">true_idx</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Gain in information resulting from a split of the parent node.</p>
<p>Weighted impurity is calculated for each side of the split, using the
impurity function set at the initialization of the model, and the total
impurity of the split is determined by the sum of these. The information
gain is the difference of the impurity of the parent and this sum :</p>
<p><span class="arithmatex">\(gain = I_{p} - w_{l}I_{l} + w_{r}I_{r}\)</span></p>
<p>The weights are calculated as the fraction of unique labels present in
the split relative to the model's set of all known labels.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>idx</code></td>
        <td><code>Any</code></td>
        <td><p>The (pandas array) index of the examples of the node
before the split.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>true_idx</code></td>
        <td><code>Any</code></td>
        <td><p>The (pandas array) index of the node's examples
for which the query condition is true. ie.: The left child's
index after the split.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">information_gain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">true_idx</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Gain in information resulting from a split of the parent node.</span>

<span class="sd">    Weighted impurity is calculated for each side of the split, using the</span>
<span class="sd">    impurity function set at the initialization of the model, and the total</span>
<span class="sd">    impurity of the split is determined by the sum of these. The information</span>
<span class="sd">    gain is the difference of the impurity of the parent and this sum :</span>

<span class="sd">    $gain = I_{p} - w_{l}I_{l} + w_{r}I_{r}$</span>

<span class="sd">    The weights are calculated as the fraction of unique labels present in</span>
<span class="sd">    the split relative to the model&#39;s set of all known labels.</span>

<span class="sd">    Args:</span>
<span class="sd">        idx (pd.array): The (pandas array) index of the examples of the node</span>
<span class="sd">            before the split.</span>
<span class="sd">        true_idx (pd.array): The (pandas array) index of the node&#39;s examples</span>
<span class="sd">            for which the query condition is true. ie.: The left child&#39;s</span>
<span class="sd">            index after the split.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_calc_impurity</span><span class="p">(</span>
        <span class="n">values</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
        <span class="n">n_total</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">impurity_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_total</span> <span class="o">*</span> <span class="n">impurity_func</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">n_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">true_impurity</span> <span class="o">=</span> <span class="n">_calc_impurity</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">true_idx</span><span class="p">],</span> <span class="n">n_total</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">impurity_func</span><span class="p">)</span>
    <span class="n">false_impurity</span> <span class="o">=</span> <span class="n">_calc_impurity</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="o">~</span><span class="n">true_idx</span><span class="p">],</span> <span class="n">n_total</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">impurity_func</span><span class="p">)</span>
    <span class="n">total_impurity</span> <span class="o">=</span> <span class="n">true_impurity</span> <span class="o">+</span> <span class="n">false_impurity</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">impurity_func</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">-</span> <span class="n">total_impurity</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="toolbox.algorithms.learning.decisiontree.DecisionTreeClassifier.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Predict classes for a set of unlabeled examples.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>data</code></td>
        <td><code>pd.DataFrame</code></td>
        <td><p>Unlabeled DataFrame of examples.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predict classes for a set of unlabeled examples.</span>

<span class="sd">    Args:</span>
<span class="sd">        data: Unlabeled DataFrame of examples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">_ix</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tree</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">leaf</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">query</span><span class="o">.</span><span class="n">operator</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">query</span><span class="o">.</span><span class="n">feature</span><span class="p">],</span> <span class="n">node</span><span class="o">.</span><span class="n">query</span><span class="o">.</span><span class="n">value</span><span class="p">):</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">left</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">node</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">right</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">label</span><span class="p">)</span>
    <span class="n">data</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">data</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="toolbox.algorithms.learning.decisiontree.gini_impurity" class="doc doc-heading">
<code class="highlight language-python"><span class="n">gini_impurity</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Gini impurity, a measure of uncertainty used by the CART algorithm.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>labels</code></td>
        <td><code>Union[List[Any], pd.Series]</code></td>
        <td><p>The labels column of the dataset</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>      <p>A measure of the probability that a label selected at random from the
distribution of labels in a dataset would incorrectly label an example from
that dataset. A Gini impurity of 0 indicates a perfectly certain dataset,
that is one with a single unique label.</p>
<p>The measure is calculated as 1 minus the sum of squared probabilities for
each unique label.</p>
<p><span class="arithmatex">\(I_{G}(p) = 1 - \sum_{i=1}^{n}p_{i}^2\)</span></p>
<p>for <span class="arithmatex">\(\mathnormal{n}\)</span> classes with <span class="arithmatex">\(i \in \{1, 2, ..., n\}\)</span></p>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">gini_impurity</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Gini impurity, a measure of uncertainty used by the CART algorithm.</span>

<span class="sd">    Args:</span>
<span class="sd">        labels: The labels column of the dataset</span>

<span class="sd">    A measure of the probability that a label selected at random from the</span>
<span class="sd">    distribution of labels in a dataset would incorrectly label an example from</span>
<span class="sd">    that dataset. A Gini impurity of 0 indicates a perfectly certain dataset,</span>
<span class="sd">    that is one with a single unique label.</span>

<span class="sd">    The measure is calculated as 1 minus the sum of squared probabilities for</span>
<span class="sd">    each unique label.</span>

<span class="sd">    $I_{G}(p) = 1 - \sum_{i=1}^{n}p_{i}^2$</span>

<span class="sd">    for $\mathnormal{n}$ classes with $i \in \{1, 2, ..., n\}$</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">((</span><span class="n">count</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">_elem</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>  <span class="c1"># type: ignore</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="toolbox.algorithms.learning.decisiontree.entropy" class="doc doc-heading">
<code class="highlight language-python"><span class="n">entropy</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents first">

      <p>Entropy, a measure of uncertainty used by the C.45 algorithm.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>labels</code></td>
        <td><code>Union[List[Any], pd.Series]</code></td>
        <td><p>The labels column of the dataset</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>      <p>A measure of the amount of information and uncertainty realized in the
outcome of drawing a value at random. An entropy of 0 indicates a dataset
which can yield no new information, that is one with a single unique label.</p>
<p>The measure is calculated as the negation of the sum of the products of the
probability of drawing the label and the base two log of the same probability
for each unique label.</p>
<p><span class="arithmatex">\(I_{G}(p) = -\sum_{i=1}^{n}p_{i} log_{2} p_{i}\)</span></p>
<p>for <span class="arithmatex">\(\mathnormal{n}\)</span> classes with <span class="arithmatex">\(i \in \{1, 2, ..., n\}\)</span></p>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/decisiontree.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">entropy</span><span class="p">(</span><span class="n">labels</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Entropy, a measure of uncertainty used by the C.45 algorithm.</span>

<span class="sd">    Args:</span>
<span class="sd">        labels: The labels column of the dataset</span>

<span class="sd">    A measure of the amount of information and uncertainty realized in the</span>
<span class="sd">    outcome of drawing a value at random. An entropy of 0 indicates a dataset</span>
<span class="sd">    which can yield no new information, that is one with a single unique label.</span>

<span class="sd">    The measure is calculated as the negation of the sum of the products of the</span>
<span class="sd">    probability of drawing the label and the base two log of the same probability</span>
<span class="sd">    for each unique label.</span>

<span class="sd">    $I_{G}(p) = -\sum_{i=1}^{n}p_{i} log_{2} p_{i}$</span>

<span class="sd">    for $\mathnormal{n}$ classes with $i \in \{1, 2, ..., n\}$</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="o">-</span><span class="nb">sum</span><span class="p">((</span><span class="n">count</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">log2</span><span class="p">((</span><span class="n">count</span> <span class="o">/</span> <span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">_elem</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
</code></pre></div>
        </details>
    </div>

  </div>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../.." class="md-footer__link md-footer__link--prev" aria-label="Previous: About" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              About
            </div>
          </div>
        </a>
      
      
        
        <a href="../evaluation/" class="md-footer__link md-footer__link--next" aria-label="Next: Evaluation" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Evaluation
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["search.suggest", "navigation.instant", "navigation.expand"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.b0710199.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.76f349be.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>