
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="canonical" href="https://example.com/machine-learning/evaluation/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.1, mkdocs-material-7.1.8">
    
    
      
        <title>Evaluation - Toolbox</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.ca7ac06f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.f1a3b89f.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#evaluation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Toolbox" class="md-header__button md-logo" aria-label="Toolbox" data-md-component="logo">
      
  <img src="../../assets/logo_white.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Toolbox
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Evaluation
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/inegm/toolbox/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    inegm/toolbox
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Toolbox" class="md-nav__button md-logo" aria-label="Toolbox" data-md-component="logo">
      
  <img src="../../assets/logo_white.png" alt="logo">

    </a>
    Toolbox
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/inegm/toolbox/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    inegm/toolbox
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      <label class="md-nav__link" for="__nav_2">
        Machine-learning
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Machine-learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Machine-learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../decision-trees/" class="md-nav__link">
        Decision-trees
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Evaluation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Evaluation
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    Classification
  </a>
  
    <nav class="md-nav" aria-label="Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier" class="md-nav__link">
    evaluate_classifier()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_model" class="md-nav__link">
    evaluate_classifier_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class" class="md-nav__link">
    evaluate_classifier_per_class()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.generate_confusion_matrix" class="md-nav__link">
    generate_confusion_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.get_classification_outcomes" class="md-nav__link">
    get_classification_outcomes()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_precision" class="md-nav__link">
    evaluate_precision()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_precision_neg" class="md-nav__link">
    evaluate_precision_neg()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_sensitivity" class="md-nav__link">
    evaluate_sensitivity()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_specificity" class="md-nav__link">
    evaluate_specificity()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_accuracy" class="md-nav__link">
    evaluate_accuracy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_f1" class="md-nav__link">
    evaluate_f1()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_all" class="md-nav__link">
    evaluate_all()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" data-md-state="indeterminate" type="checkbox" id="__nav_3" checked>
      
      <label class="md-nav__link" for="__nav_3">
        Optimization
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Optimization" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Optimization
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../optimization/particle-swarm/" class="md-nav__link">
        Particle-swarm
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" data-md-state="indeterminate" type="checkbox" id="__nav_4" checked>
      
      <label class="md-nav__link" for="__nav_4">
        Sorting
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Sorting" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Sorting
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../../sorting/quicksort/" class="md-nav__link">
        quicksort
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#classification" class="md-nav__link">
    Classification
  </a>
  
    <nav class="md-nav" aria-label="Classification">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier" class="md-nav__link">
    evaluate_classifier()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_model" class="md-nav__link">
    evaluate_classifier_model()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class" class="md-nav__link">
    evaluate_classifier_per_class()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.generate_confusion_matrix" class="md-nav__link">
    generate_confusion_matrix()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.get_classification_outcomes" class="md-nav__link">
    get_classification_outcomes()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_precision" class="md-nav__link">
    evaluate_precision()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_precision_neg" class="md-nav__link">
    evaluate_precision_neg()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_sensitivity" class="md-nav__link">
    evaluate_sensitivity()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_specificity" class="md-nav__link">
    evaluate_specificity()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_accuracy" class="md-nav__link">
    evaluate_accuracy()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_f1" class="md-nav__link">
    evaluate_f1()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox.algorithms.learning.evaluation.evaluate_all" class="md-nav__link">
    evaluate_all()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/inegm/toolbox/edit/master/docs/machine-learning/evaluation.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <h1 id="evaluation">Evaluation</h1>
<h2 id="classification">Classification</h2>


  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_classifier" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_classifier</span><span class="p">(</span><span class="n">predict_df</span><span class="p">,</span> <span class="n">predict_col</span><span class="p">,</span> <span class="n">actual_col</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Evaluates a classification model overall and for each of the its classes. It
is capable of evaluating both binary and multi-class classifiers.</p>
<p>This function wraps:</p>
<ul>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_model">evaluate_classifier_model</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class">evaluate_classifier_per_class</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.generate_confusion_matrix">generate_confusion_matrix</a></li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>predict_df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A DataFrame containing a set of features, their classes as
predicted by the classification model, and the actual classes
correctly labeling each example.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>predict_col</code></td>
        <td><code>str</code></td>
        <td><p>The name of the column holding the predicted classes.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>actual_col</code></td>
        <td><code>str</code></td>
        <td><p>The name of the column holding the actual classes.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>verbose</code></td>
        <td><code>bool</code></td>
        <td><p>Whether or not to print out the results.</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[pandas.core.series.Series, pandas.core.frame.DataFrame, pandas.core.frame.DataFrame]</code></td>
      <td><p>A tuple containing:</p>
<ul>
<li><code>model_eval</code></li>
<li><code>class_eval</code></li>
<li><code>confusion_matrix</code></li>
</ul></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <pre><code>MODEL

Precision           mean        0.657538
                    weighted    0.666667
Precision negative  mean        0.657538
                    weighted    0.648410
Sensitivity         mean        0.657538
                    weighted    0.666667
Specificity         mean        0.657538
                    weighted    0.648410
Accuracy            mean        0.666667
                    weighted    0.666667
F1-score            mean        0.657538
                    weighted    0.666667

CLASSES

                            No         Yes
True Positives      122.000000   74.000000
True Negatives       74.000000  122.000000
False Positives      49.000000   49.000000
False Negatives      49.000000   49.000000
Precision             0.713450    0.601626
Precision negative    0.601626    0.713450
Sensitivity           0.713450    0.601626
Specificity           0.601626    0.713450
Accuracy              0.666667    0.666667
F1-score              0.713450    0.601626
Weight (actual)       0.581633    0.418367

CONFUSION MATRIX

        No  Yes
actual
No      122   49
Yes      49   74
</code></pre>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_classifier</span><span class="p">(</span>
    <span class="n">predict_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">predict_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">actual_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates a classification model overall and for each of the its classes. It</span>
<span class="sd">    is capable of evaluating both binary and multi-class classifiers.</span>

<span class="sd">    This function wraps:</span>

<span class="sd">    - [evaluate_classifier_model]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_classifier_model]</span>
<span class="sd">    - [evaluate_classifier_per_class]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class]</span>
<span class="sd">    - [generate_confusion_matrix]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.generate_confusion_matrix]</span>

<span class="sd">    Args:</span>
<span class="sd">        predict_df: A DataFrame containing a set of features, their classes as</span>
<span class="sd">            predicted by the classification model, and the actual classes</span>
<span class="sd">            correctly labeling each example.</span>
<span class="sd">        predict_col: The name of the column holding the predicted classes.</span>
<span class="sd">        actual_col: The name of the column holding the actual classes.</span>
<span class="sd">        verbose: Whether or not to print out the results.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple containing:</span>

<span class="sd">        - `model_eval`</span>
<span class="sd">        - `class_eval`</span>
<span class="sd">        - `confusion_matrix`</span>

<span class="sd">    Examples:</span>

<span class="sd">        ```</span>
<span class="sd">        MODEL</span>

<span class="sd">        Precision           mean        0.657538</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        Precision negative  mean        0.657538</span>
<span class="sd">                            weighted    0.648410</span>
<span class="sd">        Sensitivity         mean        0.657538</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        Specificity         mean        0.657538</span>
<span class="sd">                            weighted    0.648410</span>
<span class="sd">        Accuracy            mean        0.666667</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        F1-score            mean        0.657538</span>
<span class="sd">                            weighted    0.666667</span>

<span class="sd">        CLASSES</span>

<span class="sd">                                    No         Yes</span>
<span class="sd">        True Positives      122.000000   74.000000</span>
<span class="sd">        True Negatives       74.000000  122.000000</span>
<span class="sd">        False Positives      49.000000   49.000000</span>
<span class="sd">        False Negatives      49.000000   49.000000</span>
<span class="sd">        Precision             0.713450    0.601626</span>
<span class="sd">        Precision negative    0.601626    0.713450</span>
<span class="sd">        Sensitivity           0.713450    0.601626</span>
<span class="sd">        Specificity           0.601626    0.713450</span>
<span class="sd">        Accuracy              0.666667    0.666667</span>
<span class="sd">        F1-score              0.713450    0.601626</span>
<span class="sd">        Weight (actual)       0.581633    0.418367</span>

<span class="sd">        CONFUSION MATRIX</span>

<span class="sd">                No  Yes</span>
<span class="sd">        actual</span>
<span class="sd">        No      122   49</span>
<span class="sd">        Yes      49   74</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">predict_df</span><span class="p">[</span><span class="n">predict_col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
        <span class="nb">set</span><span class="p">(</span><span class="n">predict_df</span><span class="p">[</span><span class="n">actual_col</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">generate_confusion_matrix</span><span class="p">(</span>
        <span class="n">predict_df</span><span class="o">=</span><span class="n">predict_df</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
        <span class="n">predict_col</span><span class="o">=</span><span class="n">predict_col</span><span class="p">,</span>
        <span class="n">actual_col</span><span class="o">=</span><span class="n">actual_col</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">class_eval</span> <span class="o">=</span> <span class="n">evaluate_classifier_per_class</span><span class="p">(</span>
        <span class="n">predict_df</span><span class="o">=</span><span class="n">predict_df</span><span class="p">,</span>
        <span class="n">confusion_matrix</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
        <span class="n">actual_col</span><span class="o">=</span><span class="n">actual_col</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">model_eval</span> <span class="o">=</span> <span class="n">evaluate_classifier_model</span><span class="p">(</span><span class="n">class_eval</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">MODEL</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">model_eval</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">CLASSES</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">class_eval</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">CONFUSION MATRIX</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">model_eval</span><span class="p">,</span> <span class="n">class_eval</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_classifier_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_classifier_model</span><span class="p">(</span><span class="n">class_eval_df</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Evaluates all (see <a href="#toolbox.algorithms.learning.evaluation.evaluate_all">evaluate_all</a>) statistical measures,
both <em>mean</em> across and <em>weighted</em> by class.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>class_eval_df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>Classifier evaluation per class, as generated by
<a href="#toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class">evaluate_classifier_per_class</a></p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Series</code></td>
      <td><p>With a multi-index, of which the 0 level is the statistical measure and
the 1 level is the method.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <pre><code>Precision           mean        0.657538
                    weighted    0.666667
Precision negative  mean        0.657538
                    weighted    0.648410
Sensitivity         mean        0.657538
                    weighted    0.666667
Specificity         mean        0.657538
                    weighted    0.648410
Accuracy            mean        0.666667
                    weighted    0.666667
F1-score            mean        0.657538
                    weighted    0.666667
</code></pre>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_classifier_model</span><span class="p">(</span><span class="n">class_eval_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates all (see [evaluate_all]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_all]) statistical measures,</span>
<span class="sd">    both *mean* across and *weighted* by class.</span>

<span class="sd">    Args:</span>
<span class="sd">        class_eval_df: Classifier evaluation per class, as generated by</span>
<span class="sd">            [evaluate_classifier_per_class]</span>
<span class="sd">            [toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class]</span>

<span class="sd">    Returns:</span>
<span class="sd">        With a multi-index, of which the 0 level is the statistical measure and</span>
<span class="sd">        the 1 level is the method.</span>

<span class="sd">    Examples:</span>
<span class="sd">        ```</span>
<span class="sd">        Precision           mean        0.657538</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        Precision negative  mean        0.657538</span>
<span class="sd">                            weighted    0.648410</span>
<span class="sd">        Sensitivity         mean        0.657538</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        Specificity         mean        0.657538</span>
<span class="sd">                            weighted    0.648410</span>
<span class="sd">        Accuracy            mean        0.666667</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        F1-score            mean        0.657538</span>
<span class="sd">                            weighted    0.666667</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Weight (actual)&quot;</span><span class="p">]</span>
    <span class="n">eval_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">):</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">):</span> <span class="p">(</span><span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Precision&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Precision negative&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">):</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Precision negative&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Precision negative&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">):</span> <span class="p">(</span>
            <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Precision negative&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span>
        <span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Sensitivity&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">):</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Sensitivity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Sensitivity&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">):</span> <span class="p">(</span><span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Sensitivity&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Specificity&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">):</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Specificity&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Specificity&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">):</span> <span class="p">(</span><span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Specificity&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">):</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">):</span> <span class="p">(</span><span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;F1-score&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">):</span> <span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;F1-score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
        <span class="p">(</span><span class="s2">&quot;F1-score&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">):</span> <span class="p">(</span><span class="n">class_eval_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;F1-score&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">eval_dict</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_classifier_per_class" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_classifier_per_class</span><span class="p">(</span><span class="n">predict_df</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">actual_col</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Evaluates all (see <a href="#toolbox.algorithms.learning.evaluation.evaluate_all">evaluate_all</a>) statistical measures,
the classification outcomes (see <a href="#toolbox.algorithms.learning.evaluation.get_classification_outcomes">get_classification_outcomes</a>), and
the relative weights for each class label.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>predict_df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A DataFrame containing a set of features, their classes as
predicted by the classification model, and the actual classes
correctly labeling each example.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>confusion_matrix</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The result of calling <a href="#toolbox.algorithms.learning.evaluation.generate_confusion_matrix">generate_confusion_matrix</a></p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>classes</code></td>
        <td><code>Set[Any]</code></td>
        <td><p>The set of all class labels</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>actual_col</code></td>
        <td><code>str</code></td>
        <td><p>The name of the column holding the actual classes.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>With the statistical measure names determining the index and a column
per class label.</p></td>
    </tr>
  </tbody>
</table>
<p><strong>Examples:</strong></p>
    <pre><code>                            No         Yes
True Positives      122.000000   74.000000
True Negatives       74.000000  122.000000
False Positives      49.000000   49.000000
False Negatives      49.000000   49.000000
Precision             0.713450    0.601626
Precision negative    0.601626    0.713450
Sensitivity           0.713450    0.601626
Specificity           0.601626    0.713450
Accuracy              0.666667    0.666667
F1-score              0.713450    0.601626
Weight (actual)       0.581633    0.418367
</code></pre>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_classifier_per_class</span><span class="p">(</span>
    <span class="n">predict_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">confusion_matrix</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">classes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">actual_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates all (see [evaluate_all]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_all]) statistical measures,</span>
<span class="sd">    the classification outcomes (see [get_classification_outcomes]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.get_classification_outcomes]), and</span>
<span class="sd">    the relative weights for each class label.</span>

<span class="sd">    Args:</span>
<span class="sd">        predict_df: A DataFrame containing a set of features, their classes as</span>
<span class="sd">            predicted by the classification model, and the actual classes</span>
<span class="sd">            correctly labeling each example.</span>
<span class="sd">        confusion_matrix: The result of calling [generate_confusion_matrix]</span>
<span class="sd">            [toolbox.algorithms.learning.evaluation.generate_confusion_matrix]</span>
<span class="sd">        classes: The set of all class labels</span>
<span class="sd">        actual_col: The name of the column holding the actual classes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        With the statistical measure names determining the index and a column</span>
<span class="sd">        per class label.</span>

<span class="sd">    Examples:</span>
<span class="sd">        ```</span>
<span class="sd">                                    No         Yes</span>
<span class="sd">        True Positives      122.000000   74.000000</span>
<span class="sd">        True Negatives       74.000000  122.000000</span>
<span class="sd">        False Positives      49.000000   49.000000</span>
<span class="sd">        False Negatives      49.000000   49.000000</span>
<span class="sd">        Precision             0.713450    0.601626</span>
<span class="sd">        Precision negative    0.601626    0.713450</span>
<span class="sd">        Sensitivity           0.713450    0.601626</span>
<span class="sd">        Specificity           0.601626    0.713450</span>
<span class="sd">        Accuracy              0.666667    0.666667</span>
<span class="sd">        F1-score              0.713450    0.601626</span>
<span class="sd">        Weight (actual)       0.581633    0.418367</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">predict_df</span><span class="p">[</span><span class="n">actual_col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">class_eval</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">class_name</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">:</span>
        <span class="n">class_eval</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">class_name</span><span class="p">:</span> <span class="p">{}})</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">get_classification_outcomes</span><span class="p">(</span>
            <span class="n">confusion_matrix</span><span class="o">=</span><span class="n">confusion_matrix</span><span class="p">,</span>
            <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span>
            <span class="n">class_name</span><span class="o">=</span><span class="n">class_name</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">eval_dict</span> <span class="o">=</span> <span class="n">evaluate_all</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
        <span class="n">eval_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;Weight (actual)&quot;</span><span class="p">:</span> <span class="n">weights</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">class_name</span><span class="p">,</span> <span class="mi">0</span><span class="p">)})</span>
        <span class="n">class_eval</span><span class="p">[</span><span class="n">class_name</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">eval_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">class_eval</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.generate_confusion_matrix" class="doc doc-heading">
<code class="highlight language-python"><span class="n">generate_confusion_matrix</span><span class="p">(</span><span class="n">predict_df</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">predict_col</span><span class="p">,</span> <span class="n">actual_col</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>The confusion matrix summarises how well a model labels examples belonging
to a set of classes. In the case of binary classification - where there are
two classes - the confusion matrix is a <span class="arithmatex">\(2*2\)</span> matrix. More generally: for
<span class="arithmatex">\(n\)</span> classes the matrix will have a shape of <span class="arithmatex">\(n*n\)</span>. Here, the <em>predicted</em>
labels determine the column headers and the <em>actual</em> labels determine the row
headers.</p>
<p>The matrix is used to calculate the classification outcomes. See
<a href="#toolbox.algorithms.learning.evaluation.get_classification_outcomes">get_classification_outcomes</a></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>predict_df</code></td>
        <td><code>DataFrame</code></td>
        <td><p>A DataFrame containing a set of features, their classes as
predicted by the classification model, and the actual classes
correctly labeling each example.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>classes</code></td>
        <td><code>Set[Any]</code></td>
        <td><p>The set of unique class labels, being the union of the unique
actual and predicted class labels.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>predict_col</code></td>
        <td><code>str</code></td>
        <td><p>The name of the column holding the predicted classes.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>actual_col</code></td>
        <td><code>str</code></td>
        <td><p>The name of the column holding the actual classes.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>For <span class="arithmatex">\(n\)</span> classes, an <span class="arithmatex">\(n*n\)</span> pd.DataFrame with <em>predicted</em> labels determining
the column headers and the <em>actual</em> labels determining the row headers.</p></td>
    </tr>
  </tbody>
</table>      <p>headers</p>

<p><strong>Examples:</strong></p>
    <p>Given a simple binary classifier with two classes 'Yes' and 'No', the
following is a possible result:</p>
<pre><code>        No  Yes
actual
No      122   49
Yes      49   74
</code></pre>

        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">generate_confusion_matrix</span><span class="p">(</span>
    <span class="n">predict_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">classes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">predict_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">actual_col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The confusion matrix summarises how well a model labels examples belonging</span>
<span class="sd">    to a set of classes. In the case of binary classification - where there are</span>
<span class="sd">    two classes - the confusion matrix is a $2*2$ matrix. More generally: for</span>
<span class="sd">    $n$ classes the matrix will have a shape of $n*n$. Here, the *predicted*</span>
<span class="sd">    labels determine the column headers and the *actual* labels determine the row</span>
<span class="sd">    headers.</span>

<span class="sd">    The matrix is used to calculate the classification outcomes. See</span>
<span class="sd">    [get_classification_outcomes]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.get_classification_outcomes]</span>

<span class="sd">    Args:</span>
<span class="sd">        predict_df: A DataFrame containing a set of features, their classes as</span>
<span class="sd">            predicted by the classification model, and the actual classes</span>
<span class="sd">            correctly labeling each example.</span>
<span class="sd">        classes: The set of unique class labels, being the union of the unique</span>
<span class="sd">            actual and predicted class labels.</span>
<span class="sd">        predict_col: The name of the column holding the predicted classes.</span>
<span class="sd">        actual_col: The name of the column holding the actual classes.</span>

<span class="sd">    Returns:</span>
<span class="sd">        For $n$ classes, an $n*n$ pd.DataFrame with *predicted* labels determining</span>
<span class="sd">        the column headers and the *actual* labels determining the row headers.</span>
<span class="sd">    headers</span>

<span class="sd">    Examples:</span>

<span class="sd">        Given a simple binary classifier with two classes &#39;Yes&#39; and &#39;No&#39;, the</span>
<span class="sd">        following is a possible result:</span>
<span class="sd">        ```</span>
<span class="sd">                No  Yes</span>
<span class="sd">        actual</span>
<span class="sd">        No      122   49</span>
<span class="sd">        Yes      49   74</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">confusion_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">classes</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_ix</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">actual</span> <span class="ow">in</span> <span class="n">predict_df</span><span class="p">[[</span><span class="n">predict_col</span><span class="p">,</span> <span class="n">actual_col</span><span class="p">]]</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
        <span class="n">confusion_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">actual</span><span class="p">][</span><span class="n">pred</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">confusion_matrix</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;actual&quot;</span>
    <span class="k">return</span> <span class="n">confusion_matrix</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.get_classification_outcomes" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_classification_outcomes</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">class_name</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Given a confusion matrix, this function counts the cases of:</p>
<ul>
<li><strong>True Positives</strong> : classifications that accurately labeled a class</li>
<li><strong>True Negatives</strong> : classifications that accurately labeled an example as
    not belonging to a class.</li>
<li><strong>False Positives</strong> : classifications that attributed the wrong label to an
    example.</li>
<li><strong>False Negatives</strong> : classifications that falsely claimed that an example
    does not belong to a class.</li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>confusion_matrix</code></td>
        <td><code>DataFrame</code></td>
        <td><p>The result of calling <a href="#toolbox.algorithms.learning.evaluation.generate_confusion_matrix">generate_confusion_matrix</a></p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>classes</code></td>
        <td><code>Set[Any]</code></td>
        <td><p>The set of all class labels</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>class_name</code></td>
        <td><code>str</code></td>
        <td><p>The name (label) of the class being evaluated.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[int, int, int, int]</code></td>
      <td><ul>
<li><code>tp</code>: Count of True Positives</li>
<li><code>tn</code>: Count of True Negatives</li>
<li><code>fp</code>: Count of False Positives</li>
<li><code>fn</code>: Count of False Negatives</li>
</ul></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_classification_outcomes</span><span class="p">(</span>
    <span class="n">confusion_matrix</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">classes</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
    <span class="n">class_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a confusion matrix, this function counts the cases of:</span>

<span class="sd">    - **True Positives** : classifications that accurately labeled a class</span>
<span class="sd">    - **True Negatives** : classifications that accurately labeled an example as</span>
<span class="sd">        not belonging to a class.</span>
<span class="sd">    - **False Positives** : classifications that attributed the wrong label to an</span>
<span class="sd">        example.</span>
<span class="sd">    - **False Negatives** : classifications that falsely claimed that an example</span>
<span class="sd">        does not belong to a class.</span>

<span class="sd">    Args:</span>
<span class="sd">        confusion_matrix: The result of calling [generate_confusion_matrix]</span>
<span class="sd">            [toolbox.algorithms.learning.evaluation.generate_confusion_matrix]</span>
<span class="sd">        classes: The set of all class labels</span>
<span class="sd">        class_name: The name (label) of the class being evaluated.</span>

<span class="sd">    Returns:</span>
<span class="sd">        - `tp`: Count of True Positives</span>
<span class="sd">        - `tn`: Count of True Negatives</span>
<span class="sd">        - `fp`: Count of False Positives</span>
<span class="sd">        - `fn`: Count of False Negatives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">excl_idx</span> <span class="o">=</span> <span class="n">classes</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="nb">set</span><span class="p">((</span><span class="n">class_name</span><span class="p">,)))</span>
    <span class="n">tp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_name</span><span class="p">,</span> <span class="n">class_name</span><span class="p">]</span>
    <span class="n">tn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">excl_idx</span><span class="p">,</span> <span class="n">excl_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">class_name</span><span class="p">,</span> <span class="n">excl_idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">excl_idx</span><span class="p">,</span> <span class="n">class_name</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_precision" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_precision</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Precision, aka Positive Predictive Value (PPV).</p>
<p><span class="arithmatex">\(PPV=\dfrac{TP}{TP + FP}\)</span></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tp</code></td>
        <td><code>int</code></td>
        <td><p>True Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fp</code></td>
        <td><code>int</code></td>
        <td><p>False Positives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_precision</span><span class="p">(</span><span class="n">tp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fp</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Precision, aka Positive Predictive Value (PPV).</span>


<span class="sd">    $PPV=\dfrac{TP}{TP + FP}$</span>

<span class="sd">    Args:</span>
<span class="sd">        tp: True Positives</span>
<span class="sd">        fp: False Positives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_precision_neg" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_precision_neg</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Negative precision, aka Negative Predictive Value (NPV).</p>
<p><span class="arithmatex">\(NPV=\dfrac{TN}{TN + FN}\)</span></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tn</code></td>
        <td><code>int</code></td>
        <td><p>True Negatives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fn</code></td>
        <td><code>int</code></td>
        <td><p>False Negatives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_precision_neg</span><span class="p">(</span><span class="n">tn</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Negative precision, aka Negative Predictive Value (NPV).</span>


<span class="sd">    $NPV=\dfrac{TN}{TN + FN}$</span>

<span class="sd">    Args:</span>
<span class="sd">        tn: True Negatives</span>
<span class="sd">        fn: False Negatives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_sensitivity" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_sensitivity</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Sensitivity, aka Recall, aka True Positive Rate (TPR).</p>
<p><span class="arithmatex">\(TPR=\dfrac{TP}{TP + FN}\)</span></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tp</code></td>
        <td><code>int</code></td>
        <td><p>True Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fn</code></td>
        <td><code>int</code></td>
        <td><p>False Negatives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_sensitivity</span><span class="p">(</span><span class="n">tp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Sensitivity, aka Recall, aka True Positive Rate (TPR).</span>

<span class="sd">    $TPR=\dfrac{TP}{TP + FN}$</span>

<span class="sd">    Args:</span>
<span class="sd">        tp: True Positives</span>
<span class="sd">        fn: False Negatives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_specificity" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_specificity</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Specificity, aka True Negative Rate (TNR).</p>
<p><span class="arithmatex">\(TNR=\dfrac{TP}{TP + FP}\)</span></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tp</code></td>
        <td><code></code></td>
        <td><p>True Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fp</code></td>
        <td><code>int</code></td>
        <td><p>False Positives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_specificity</span><span class="p">(</span><span class="n">tn</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fp</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Specificity, aka True Negative Rate (TNR).</span>

<span class="sd">    $TNR=\dfrac{TP}{TP + FP}$</span>

<span class="sd">    Args:</span>
<span class="sd">        tp: True Positives</span>
<span class="sd">        fp: False Positives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tn</span> <span class="o">/</span> <span class="p">(</span><span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_accuracy" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Accuracy (ACC).</p>
<p><span class="arithmatex">\(ACC=\dfrac{TP + TN}{TP + TN + FP + FN}\)</span></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tp</code></td>
        <td><code>int</code></td>
        <td><p>True Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>tn</code></td>
        <td><code>int</code></td>
        <td><p>True Negatives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fp</code></td>
        <td><code>int</code></td>
        <td><p>False Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fn</code></td>
        <td><code>int</code></td>
        <td><p>False Negatives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_accuracy</span><span class="p">(</span><span class="n">tp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">tn</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Accuracy (ACC).</span>

<span class="sd">    $ACC=\dfrac{TP + TN}{TP + TN + FP + FN}$</span>

<span class="sd">    Args:</span>
<span class="sd">        tp: True Positives</span>
<span class="sd">        tn: True Negatives</span>
<span class="sd">        fp: False Positives</span>
<span class="sd">        fn: False Negatives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_f1" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_f1</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>F1-score.</p>
<p><em>F1-score</em> <span class="arithmatex">\(=\dfrac{2TP}{2TP + FP + FN}\)</span></p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tp</code></td>
        <td><code>int</code></td>
        <td><p>True Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fp</code></td>
        <td><code>int</code></td>
        <td><p>False Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fn</code></td>
        <td><code>int</code></td>
        <td><p>False Negatives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_f1</span><span class="p">(</span><span class="n">tp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;F1-score.</span>

<span class="sd">    *F1-score* $=\dfrac{2TP}{2TP + FP + FN}$</span>

<span class="sd">    Args:</span>
<span class="sd">        tp: True Positives</span>
<span class="sd">        fp: False Positives</span>
<span class="sd">        fn: False Negatives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ZeroDivisionError</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h3 id="toolbox.algorithms.learning.evaluation.evaluate_all" class="doc doc-heading">
<code class="highlight language-python"><span class="n">evaluate_all</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents first">

      <p>Evaluates the following statistical measures:</p>
<ul>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_precision">precision</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_precision_neg">negative precision</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_sensitivity">sensitivity (recall)</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_specificity">specificity</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_accuracy">accuracy</a></li>
<li><a href="#toolbox.algorithms.learning.evaluation.evaluate_f1">f1-score</a></li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>tp</code></td>
        <td><code>int</code></td>
        <td><p>True Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>tn</code></td>
        <td><code>int</code></td>
        <td><p>True Negatives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fp</code></td>
        <td><code>int</code></td>
        <td><p>False Positives</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>fn</code></td>
        <td><code>int</code></td>
        <td><p>False Negatives</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>dict</code></td>
      <td><p>See source for dictionary keys.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>toolbox/algorithms/learning/evaluation.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_all</span><span class="p">(</span><span class="n">tp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">tn</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fp</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">fn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates the following statistical measures:</span>

<span class="sd">    - [precision]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_precision]</span>
<span class="sd">    - [negative precision]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_precision_neg]</span>
<span class="sd">    - [sensitivity (recall)]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_sensitivity]</span>
<span class="sd">    - [specificity]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_specificity]</span>
<span class="sd">    - [accuracy]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_accuracy]</span>
<span class="sd">    - [f1-score]</span>
<span class="sd">    [toolbox.algorithms.learning.evaluation.evaluate_f1]</span>

<span class="sd">    Args:</span>
<span class="sd">        tp: True Positives</span>
<span class="sd">        tn: True Negatives</span>
<span class="sd">        fp: False Positives</span>
<span class="sd">        fn: False Negatives</span>

<span class="sd">    Returns:</span>
<span class="sd">        See source for dictionary keys.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;True Positives&quot;</span><span class="p">:</span> <span class="n">tp</span><span class="p">,</span>
        <span class="s2">&quot;True Negatives&quot;</span><span class="p">:</span> <span class="n">tn</span><span class="p">,</span>
        <span class="s2">&quot;False Positives&quot;</span><span class="p">:</span> <span class="n">fp</span><span class="p">,</span>
        <span class="s2">&quot;False Negatives&quot;</span><span class="p">:</span> <span class="n">fn</span><span class="p">,</span>
        <span class="s2">&quot;Precision&quot;</span><span class="p">:</span> <span class="n">evaluate_precision</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">),</span>
        <span class="s2">&quot;Precision negative&quot;</span><span class="p">:</span> <span class="n">evaluate_precision_neg</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">fn</span><span class="p">),</span>
        <span class="s2">&quot;Sensitivity&quot;</span><span class="p">:</span> <span class="n">evaluate_sensitivity</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fn</span><span class="p">),</span>
        <span class="s2">&quot;Specificity&quot;</span><span class="p">:</span> <span class="n">evaluate_specificity</span><span class="p">(</span><span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">),</span>
        <span class="s2">&quot;Accuracy&quot;</span><span class="p">:</span> <span class="n">evaluate_accuracy</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">),</span>
        <span class="s2">&quot;F1-score&quot;</span><span class="p">:</span> <span class="n">evaluate_f1</span><span class="p">(</span><span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span><span class="p">),</span>
    <span class="p">}</span>
</code></pre></div>
        </details>
    </div>

  </div>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../decision-trees/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Decision-trees" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Decision-trees
            </div>
          </div>
        </a>
      
      
        
        <a href="../../optimization/particle-swarm/" class="md-footer__link md-footer__link--next" aria-label="Next: Particle-swarm" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Particle-swarm
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["search.suggest", "navigation.instant", "navigation.expand"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.b0710199.min.js", "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.76f349be.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>